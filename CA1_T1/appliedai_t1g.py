# -*- coding: utf-8 -*-
"""AppliedAI_T1G.ipynb

Automatically generated by Colab.
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder

# news data with labels
df = pd.read_csv('combined_dataset.csv')

# Basic data exploration
print(f"Dataset shape: {df.shape}")
print(f"\nLabel distribution:\n{df['label'].value_counts()}")
print(f"\nSample content:\n{df.head()}")

# Text preprocessing function
import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
import nltk

# Download required NLTK data
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

lemmantiser = WordNetLemmatizer()
stop_words = set(stopwords.words('english'))

def preprocess_text(text):
    # convert to lowercase
    text = text.lower()
    # Remove urls
    text = re.sub(r'http\S+|www\S+|https\S+', '', text)
    # remove special chars/digits
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    # # remove extra whitespace
    # text = ' '.join(text.split())

    # tokenise
    tokens = text.split()

    # remove stop words and lemmatise
    cleaned_tokens = [lemmantiser.lemmatize(word) for word in tokens if word not in stop_words and len(word) > 2]
    return ' '.join(cleaned_tokens)

#preprocessing
df['cleaned_content'] = df['content'].apply(preprocess_text)

# Split data (80-20 train-test split)
X_train, X_test, y_train, y_test = train_test_split(
    df['cleaned_content'],
    df['label'],
    test_size=0.2,
    random_state=42,
    stratify=df['label']  # here we startify based on label which ensures balanced split
)

print(f"\nTraining set size: {len(X_train)}")
print(f"Test set size: {len(X_test)}")

# TF-IDF Vectorisation
tfidf = TfidfVectorizer(
    max_features=15000,  # Top 15000 most important words
    min_df=3,           # Ignore terms appearing in less than 3 documents
    max_df=0.9,         # ignore terms appearing in more than 90% of documents
    ngram_range=(1, 2),  # unigrams and bigrams
    sublinear_tf=True,
    strip_accents='unicode'
)

X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)

print(f"TF-IDF matrix shape: {X_train_tfidf.shape}")

# Dictionary to store models and results
models = {}
results = {}

# 1 Logistic Regression
print("\nTraining Logistic Regression:")
lr_model = LogisticRegression(max_iter=1000, random_state=42, C=10.0, solver='saga')
lr_model.fit(X_train_tfidf, y_train)
models['Logistic Regression'] = lr_model

y_pred_lr = lr_model.predict(X_test_tfidf)
results['Logistic Regression'] = {
    'accuracy': accuracy_score(y_test, y_pred_lr),
    'predictions': y_pred_lr
}

print(f"Accuracy: {results['Logistic Regression']['accuracy']:.4f}")
print(f"\nClassification Report:\n{classification_report(y_test, y_pred_lr)}")

# 2. Random Forest
print("\nTraining Random Forest:")
rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=50)
rf_model.fit(X_train_tfidf, y_train)
models['Random Forest'] = rf_model

y_pred_rf = rf_model.predict(X_test_tfidf)
results['Random Forest'] = {
    'accuracy': accuracy_score(y_test, y_pred_rf),
    'predictions': y_pred_rf
}

print(f"Accuracy: {results['Random Forest']['accuracy']:.4f}")
print(f"\nClassification Report:\n{classification_report(y_test, y_pred_rf)}")

# 3. Support Vector Machine
print("\nTraining SVM:")
svm_model = SVC(kernel='linear', random_state=42, C=1.0)
svm_model.fit(X_train_tfidf, y_train)
models['SVM'] = svm_model

y_pred_svm = svm_model.predict(X_test_tfidf)
results['SVM'] = {
    'accuracy': accuracy_score(y_test, y_pred_svm),
    'predictions': y_pred_svm
}

print(f"Accuracy: {results['SVM']['accuracy']:.4f}")
print(f"\nClassification Report:\n{classification_report(y_test, y_pred_svm)}")

# 4 XGBoost
print("\nTraining XGB:")

le = LabelEncoder()
y_train_enc = le.fit_transform(y_train)
y_test_enc = le.transform(y_test)

xgb_model = XGBClassifier(
    n_estimators=200,
    learning_rate=0.1,
    max_depth=6,
    random_state=42,
    eval_metric='mlogloss'
)

xgb_model.fit(X_train_tfidf, y_train_enc)
models['XGB'] = xgb_model
y_pred_enc = xgb_model.predict(X_test_tfidf)
y_pred_xgb = le.inverse_transform(y_pred_enc) # converting back to labels for reportung

results['XGB'] = {
    'accuracy': accuracy_score(y_test, y_pred_xgb),
    'accuracy_enc': accuracy_score(y_test_enc, y_pred_enc),
    'predictions': y_pred_xgb
}


print(f"Accuracy: {results['XGB']['accuracy']:.4f}")
print(f"Accuracy: {results['XGB']['accuracy_enc']:.4f}")
print(f"\nClassification Report:\n{classification_report(y_test, y_pred_xgb)}")

# Compare model accuracies
model_names = list(results.keys())
accuracies = [results[model]['accuracy'] for model in model_names]

plt.figure(figsize=(10, 6))
plt.bar(model_names, accuracies, color=['#3498db', '#2ecc71', '#e74c3c'])
plt.ylabel('Accuracy', fontsize=12)
plt.title('ML Model Comparison for News Bias Classification', fontsize=14)
plt.ylim(0, 1)
for i, v in enumerate(accuracies):
    plt.text(i, v + 0.01, f'{v:.3f}', ha='center', fontsize=11)
plt.tight_layout()
plt.savefig('model_comparison.png', dpi=300)
plt.show()

# Confusion matrix for best model
best_model_name = max(results, key=lambda x: results[x]['accuracy'])
print(f"\n=== Confusion Matrix for {best_model_name} ===")

cm = confusion_matrix(y_test, results[best_model_name]['predictions'])
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=lr_model.classes_,
            yticklabels=lr_model.classes_)
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.title(f'Confusion Matrix - {best_model_name}')
plt.tight_layout()
plt.savefig('confusion_matrix.png', dpi=300)
plt.show()
